{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36c5db6a-2ed4-4050-aef4-81d10bb51331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Load & initial cleanup\n",
    "df = pd.read_csv(\"sample_data.csv\")\n",
    "df.columns = df.columns.str.strip()\n",
    "df['END DATE'] = pd.to_datetime(df['END DATE'], errors='coerce')\n",
    "\n",
    "# 2. Ensure numeric prices & create SKU key\n",
    "price_cols = ['NON-PROMO PRICE', 'PROMO PRICE', 'AVG PRICE']\n",
    "df[price_cols] = df[price_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "df['Brand_Pack_PackType'] = (\n",
    "    df['BRAND'] + ' x ' +\n",
    "    df['ACTUAL PACK SIZE'].astype(str) + ' x ' +\n",
    "    df['PACK TYPE'].astype(str)\n",
    ")\n",
    "\n",
    "# 3. Baseline price (80th percentile non-promo price)\n",
    "baseline_price = (\n",
    "    df.groupby(['Markets','YEAR','Brand_Pack_PackType'])['NON-PROMO PRICE']\n",
    "      .quantile(0.8)\n",
    "      .reset_index(name='Baseline Price')\n",
    ")\n",
    "df = df.merge(baseline_price, on=['Markets','YEAR','Brand_Pack_PackType'], how='left')\n",
    "\n",
    "# 4. Identify promo weeks\n",
    "df['Promo Vol Check'] = (df['Sales Units Any Promo'] > 0.5 * df['Sales Units']).map({True:'Y', False:'N'})\n",
    "df['Promo 5% Deviation Check'] = (df['PROMO PRICE'] < 0.95 * df['NON-PROMO PRICE']).map({True:'Y', False:'N'})\n",
    "df['Promo Week Check'] = ((df['Promo Vol Check']=='Y') & (df['Promo 5% Deviation Check']=='Y')).map({True:'Y', False:'N'})\n",
    "\n",
    "# 5. Baseline volume (mean non-promo units)\n",
    "df['Sales Units No Promo'] = pd.to_numeric(df['Sales Units No Promo'], errors='coerce')\n",
    "non_promo = df[df['Promo Week Check']=='N']\n",
    "baseline_vol = (\n",
    "    non_promo.groupby(['Markets','YEAR','Brand_Pack_PackType'])['Sales Units No Promo']\n",
    "             .mean()\n",
    "             .reset_index(name='Baseline Volume')\n",
    ")\n",
    "df = df.merge(baseline_vol, on=['Markets','YEAR','Brand_Pack_PackType'], how='left')\n",
    "\n",
    "# 6. Filter anomalies & compute uplift\n",
    "df['Erase Anomaly'] = ((df['Baseline Volume']>df['Sales Units']) & (df['Baseline Price']<df['PROMO PRICE'])).map({True:'Y', False:'N'})\n",
    "df['Uplift'] = df.apply(\n",
    "    lambda r: r['Sales Units'] - r['Baseline Volume']\n",
    "              if (r['Promo Week Check']=='Y') and (r['Erase Anomaly']=='N')\n",
    "              else np.nan,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# 7. Create a stable “promo depth” column on df before slicing\n",
    "df['promo_depth_pct'] = 1.0 - (df['PROMO PRICE'] / df['Baseline Price'])\n",
    "\n",
    "# 8. Build valid promo-week table\n",
    "valid = df[(df['Promo Week Check']=='Y') & (df['Erase Anomaly']=='N')].copy()\n",
    "valid.sort_values(['Markets','YEAR','Brand_Pack_PackType','END DATE'], inplace=True)\n",
    "valid['Date_Gap'] = valid.groupby(['Markets','YEAR','Brand_Pack_PackType'])['END DATE'].diff().dt.days.fillna(0)\n",
    "valid['New_Event'] = (valid['Date_Gap']>7).astype(int)\n",
    "valid['Event_ID'] = valid.groupby(['Markets','YEAR','Brand_Pack_PackType'])['New_Event'].cumsum()\n",
    "valid['Valid Event Uplift'] = ((valid['Uplift'].notna()) & (valid['Uplift']>0.2*valid['Baseline Volume'])).map({True:'Y',False:'N'})\n",
    "valid = valid[valid['Valid Event Uplift']=='Y']\n",
    "\n",
    "# 9. Compute event-level median depth and bucket\n",
    "event_depth = (\n",
    "    valid\n",
    "      .groupby(['Markets','YEAR','Brand_Pack_PackType','Event_ID'])['promo_depth_pct']\n",
    "      .median()\n",
    "      .reset_index(name='event_median_depth')\n",
    ")\n",
    "\n",
    "bins = [0.05,0.10,0.15,0.20,0.25,0.30,0.35,0.40,0.45,\n",
    "        0.50,0.55,0.60,0.65,0.70,0.75,0.80,1.10]\n",
    "labels = ['5–9.99%','10–14.99%','15–19.99%','20–24.99%','25–29.99%','30–34.99%',\n",
    "          '35–39.99%','40–44.99%','45–49.99%','50–54.99%','55–59.99%','60–64.99%',\n",
    "          '65–69.99%','70–74.99%','75–79.99%','80%+']\n",
    "event_depth['depth_bucket'] = pd.cut(\n",
    "    event_depth['event_median_depth'],\n",
    "    bins=bins,\n",
    "    labels=labels,\n",
    "    right=False\n",
    ")\n",
    "\n",
    "valid = valid.merge(\n",
    "    event_depth,\n",
    "    on=['Markets','YEAR','Brand_Pack_PackType','Event_ID'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 10. Compute event duration & duration buckets\n",
    "event_duration = valid.groupby(['Markets','YEAR','Brand_Pack_PackType','Event_ID']) \\\n",
    "                      .size() \\\n",
    "                      .reset_index(name='Event Duration (weeks)')\n",
    "valid = valid.merge(\n",
    "    event_duration,\n",
    "    on=['Markets','YEAR','Brand_Pack_PackType','Event_ID'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "event_stats = (\n",
    "    valid.groupby(['Markets','YEAR','Brand_Pack_PackType','Event_ID'])\n",
    "         .agg(\n",
    "             Event_Duration=('Event_ID','size'),\n",
    "             Max_Depth=('promo_depth_pct','max')\n",
    "         )\n",
    "         .reset_index()\n",
    ")\n",
    "event_stats['Duration Bucket'] = pd.cut(\n",
    "    event_stats['Event_Duration'],\n",
    "    bins=[0,3,6,np.inf],\n",
    "    labels=['Short','Medium','Long'],\n",
    "    right=True\n",
    ")\n",
    "event_stats['Depth Bucket'] = pd.cut(\n",
    "    event_stats['Max_Depth'],\n",
    "    bins=[-1,0.10,0.20,1.10],\n",
    "    labels=['Shallow','Medium','Deep'],\n",
    "    right=False\n",
    ")\n",
    "\n",
    "valid = valid.merge(\n",
    "    event_stats[['Markets','YEAR','Brand_Pack_PackType','Event_ID','Duration Bucket','Depth Bucket']],\n",
    "    on=['Markets','YEAR','Brand_Pack_PackType','Event_ID'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 11. Save outputs\n",
    "df.to_excel(\"sample_data_cleaned.xlsx\", index=False)\n",
    "valid.to_excel(\"sample_data_events.xlsx\", sheet_name=\"Weekly\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a3ab7d-e238-4887-948d-0c5bde1f66e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
